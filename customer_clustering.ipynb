{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans, AgglomerativeClustering\nfrom sklearn.metrics import silhouette_score\nimport scipy.cluster.hierarchy as sch",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Load the dataset\ndata = pd.read_csv('../data/renttherunway.csv')\n\n# Display basic information\nprint(data.head())\nprint(data.info())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Check for duplicate rows and drop them\ndata = data.drop_duplicates()\n\n# Drop unnecessary columns\ndata = data.drop(['user_id', 'item_id', 'review_text', 'review_date'], axis=1)\n\n# Clean 'weight' column\ndata['weight'] = data['weight'].str.replace('lbs', '').astype(float)\n\n# Group 'party: cocktail' with 'party' in 'rented for'\ndata['rented for'] = data['rented for'].replace({'party: cocktail': 'party'})\n\n# Convert 'height' to inches\ndata['height'] = data['height'].str.replace(\"'\", \".\").astype(float) * 12\n\n# Handle missing values\ndata.fillna(data.mean(), inplace=True)\n\n# Check statistical summary\nprint(data.describe())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Treat outliers in 'age'\nq1, q3 = np.percentile(data['age'], [25, 75])\niqr = q3 - q1\nlower_bound = q1 - 1.5 * iqr\nupper_bound = q3 + 1.5 * iqr\ndata['age'] = np.clip(data['age'], lower_bound, upper_bound)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Plot distribution of 'rented for'\nsns.countplot(data['rented for'])\nplt.title('Distribution of Rented For')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Encode categorical variables\nencoder = LabelEncoder()\nfor column in ['rented for', 'body type', 'category', 'fit']:\n    data[column] = encoder.fit_transform(data[column])\n\n# Standardize the data\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Perform PCA to reduce dimensions\npca = PCA(n_components=0.95)\npca_data = pca.fit_transform(scaled_data)\n\n# Explained variance\nprint(f\"Explained variance by PCA components: {sum(pca.explained_variance_ratio_)}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Elbow plot to determine optimal K\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters=i, random_state=42)\n    kmeans.fit(pca_data)\n    wcss.append(kmeans.inertia_)\n\nplt.plot(range(1, 11), wcss)\nplt.title('Elbow Plot')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()\n\n# Build KMeans model with optimal K\nkmeans = KMeans(n_clusters=4, random_state=42)\nkmeans.fit(pca_data)\ndata['KMeans_Cluster'] = kmeans.labels_\n\n# Silhouette score\nsilhouette_avg = silhouette_score(pca_data, kmeans.labels_)\nprint(f\"Silhouette Score for KMeans: {silhouette_avg}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Dendrogram to determine optimal K\ndendrogram = sch.dendrogram(sch.linkage(pca_data[:1000], method='ward'))\nplt.title('Dendrogram')\nplt.xlabel('Samples')\nplt.ylabel('Distance')\nplt.show()\n\n# Build Agglomerative model\nagglom = AgglomerativeClustering(n_clusters=4, affinity='euclidean', linkage='ward')\ndata['Agglomerative_Cluster'] = agglom.fit_predict(pca_data)\n\n# Silhouette score\nsilhouette_avg = silhouette_score(pca_data, agglom.labels_)\nprint(f\"Silhouette Score for Agglomerative Clustering: {silhouette_avg}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Bivariate analysis for clusters\nsns.boxplot(x='KMeans_Cluster', y='age', data=data)\nplt.title('Age Distribution Across KMeans Clusters')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}